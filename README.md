# General Motors Telemetry Data Processing
 - This project is focused on processing telemetry data generated by third-party IoT devices installed in General Motors' heavy vehicles. The telemetry data is sent in JSON format to an AWS S3 storage bucket, and we need to move it to General Motors' Azure cloud, validate it, and store it in a SQL database.
## Architecture
The data processing pipeline consists of the following components:
- **Source:** AWS S3 storage bucket where JSON telemetry data is stored.
- **Landing:** Azure Storage Account where the telemetry data is copied using Azure Data Factory.
- **Validation:** Azure Function triggered by a storage-based trigger that reads the telemetry data from the landing folder, validates it, and moves it to the staging folder if it's valid or to the rejected folder otherwise.
-**Staging:** Azure Storage Account where the validated telemetry data is copied using Azure Data Factory.
-**Destination:** Azure SQL Database where the validated telemetry data is stored.
Here's a diagram of the pipeline architecture:

## Setup
To deploy this data processing pipeline, you'll need an Azure subscription and the following Azure services:
- Azure Data Factory
- Azure Storage Account
- Azure Function
- Azure SQL Database
You'll also need to set up the following resources:
- AWS S3 storage bucket: Create an AWS S3 storage bucket and configure it to receive telemetry data from the third-party IoT devices installed in General Motors' heavy vehicles.
- Azure Storage Account: Create an Azure Storage Account and set up the following containers:
- Landing: Create a container named landing to store the telemetry data copied from the AWS S3 storage bucket using Azure Data Factory.
- Staging: Create a container named staging to store the validated telemetry data that is ready to be copied to the Azure SQL Database.
- Rejected: Create a container named rejected to store the telemetry data that is rejected by the validation process.
- Azure SQL Database: Create an Azure SQL Database and set up the following table to store the validated telemetry data: sql  Copy codeCREATE TABLE TelemetryData (
    VehicleId INT NOT NULL,
    Timestamp DATETIME NOT NULL,
    Latitude FLOAT NOT NULL,
    Longitude FLOAT NOT NULL,
    Speed FLOAT NOT NULL,
    EngineRpm FLOAT NOT NULL,
    Acceleration FLOAT NOT NULL,
    PRIMARY KEY (VehicleId, Timestamp)
);
- Azure Function: Create an Azure Function and set up the following:
- Runtime stack: Choose .NET Core 3.1.
- Trigger: Choose Azure Blob Storage trigger.
- Input: Set the path to the landing container in the Azure Storage Account.
- Output: Set the path to the staging and rejected containers in the Azure Storage Account.
## Azure Data Factory: Create an Azure Data Factory and set up the following:
- Source: Set up a connection to the AWS S3 storage bucket and create a dataset pointing to the bucket.
- Destination: Set up a connection to the Azure Storage Account and create datasets pointing to the landing and staging containers.
- Copy data pipeline: Create a pipeline that copies data from the AWS S3 storage bucket to the landing container in the Azure Storage Account.
- Move data pipeline: Create a pipeline that moves validated data from the staging container to the Azure SQL Database.
### References: 
Udemy Course on Azure Data Engineering by Deepak Goyal
